# Feature Ideas & Development Notes

This document tracks potential features, improvements, and implementation ideas for tabelog.

## ğŸ¯ Planned Features

### High Priority

### Medium Priority

### Low Priority / Future Considerations
- [ ] **CLI tool for quick restaurant searches**
  - Simple command-line interface: `tabelog search "æ±äº¬ å¯¿å¸" --min-rating 4.0`
  - Output formats: table, JSON, CSV
  - Tool: Use `typer` (already in dependencies)

- [ ] **Caching and performance optimization**
  - Built-in response caching (not just `@cache` on one function)
  - Configurable cache backend (memory, Redis, file-based)
  - Rate limiting to avoid being blocked
  - Connection pooling for multiple requests

- [ ] **Retry and resilience mechanisms**
  - Auto-retry on transient failures
  - Exponential backoff
  - Circuit breaker pattern
  - Tool: `tenacity` library (per user preferences)

- [ ] **Export and integration features**
  - Export to multiple formats: JSON, CSV, Excel, SQLite
  - Pandas DataFrame conversion
  - SQLAlchemy model integration
  - Google Sheets export

- [ ] **Enhanced testing**
  - Record/replay HTTP interactions (VCR.py)
  - HTML fixtures for offline testing
  - Performance benchmarks
  - Integration tests with real Tabelog (run manually)

- [ ] **Documentation improvements**
  - API reference docs (Sphinx or MkDocs)
  - Jupyter notebook examples
  - Video tutorials
  - Migration guide for API v2.0

- [ ] **Advanced Tabelog features**
  - Area-based browsing (not just search)
  - Restaurant rankings (top 100, etc.)
  - Map/location-based search
  - User profile scraping (reviewer info)
  - Restaurant comparison tool

- [ ] **Multi-platform support**
  - Support other restaurant sites (Gurunavi, Retty, Hot Pepper Gourmet)
  - Unified interface across platforms
  - Cross-platform comparison

## ğŸ’¡ Ideas & Brainstorming

### Performance
- **Concurrent multi-page scraping**: Use `asyncio.gather()` to fetch multiple pages simultaneously
  ```python
  # Current: sequential page fetching
  for page in range(1, max_pages + 1):
      results = await fetch_page(page)

  # Proposed: parallel fetching
  tasks = [fetch_page(p) for p in range(1, max_pages + 1)]
  all_results = await asyncio.gather(*tasks)
  ```
- **Connection pooling**: Reuse HTTP connections across requests (httpx already supports this)
- **Streaming responses**: For large result sets, yield results as they're parsed
- **Selective parsing**: Only parse needed fields to reduce CPU time
- **Response compression**: Enable gzip/brotli compression in HTTP headers

### User Experience
- **Terminal UI (TUI) Application**: Build an interactive terminal interface for restaurant search
  - **Framework**: `textual` - Modern Python TUI framework with rich widgets
  - **Key features**:
    - Search bar with area/keyword input
    - Filterable results table (sort by rating, review count, price)
    - Detail view panel showing full restaurant info
    - Navigation: arrow keys, vim-style (j/k), tab switching
    - Pagination for large result sets
    - Export selected restaurants to JSON/CSV
  - **UI Layout ideas**:
    - Split view: search filters (left) + results list (right)
    - Bottom panel: restaurant detail view on selection
    - Top bar: current search criteria, total results count
    - Status bar: keyboard shortcuts help
  - **Restaurant detail navigation**:
    - Press Enter on selected restaurant to open detail view
    - Tab-based navigation: åŸºæœ¬æƒ…å ± / å£ã‚³ãƒŸ / ãƒ¡ãƒ‹ãƒ¥ãƒ¼ / ã‚³ãƒ¼ã‚¹ / å†™çœŸ
    - Keyboard shortcuts: 1-5 or Tab/Shift+Tab to switch tabs
    - Scrollable content for long reviews/menus
    - Press 'b' or Esc to go back to search results
  - **Technical approach**:
    - New module: `src/tabelog/tui.py` or separate `tabelog-tui` package
    - Async integration with `SearchRequest.do()` for non-blocking search
    - CLI entry point: `tabelog search-tui` or standalone `tabelog-tui` command
    - Configuration: save/load favorite search queries
  - **Dependencies to add**:
    - `textual` - TUI framework
    - Optional: `rich` for enhanced terminal rendering (textual already includes it)

### Architecture

- **API Design Improvements**: Current API can be more developer-friendly and Pythonic

  **Current issues**:
  - Method names `do()` / `do_sync()` are not intuitive
  - Too many parameters in dataclass constructors (14+ parameters)
  - No fluent/builder pattern for constructing queries
  - Missing convenience factory methods
  - `SearchResponse` lacks filtering/sorting utilities
  - No custom exception types for better error handling
  - `query_restaurants()` has 14 parameters (hard to remember, error-prone)

  **Proposed improvements**:

  1. **Better method naming**:
     ```python
     # Current
     request.do()         # unclear
     request.do_sync()    # unclear

     # Proposed
     request.search()     # or execute() / run()
     request.search_sync()  # or execute_sync() / run_sync()
     ```

  2. **Builder pattern for fluent API**:
     ```python
     # Current
     request = RestaurantSearchRequest(
         area="æ±äº¬",
         keyword="å¯¿å¸",
         price_range=PriceRange.DINNER_5000_6000,
         has_private_room=True,
         card_accepted=True,
     )

     # Proposed (fluent)
     request = (
         RestaurantSearch()
         .in_area("æ±äº¬")
         .with_keyword("å¯¿å¸")
         .price_range(PriceRange.DINNER_5000_6000)
         .require_private_room()
         .accepts_cards()
     )
     # or chainable
     results = await RestaurantSearch().in_area("æ±äº¬").with_keyword("å¯¿å¸").search()
     ```

  3. **Factory methods for common use cases**:
     ```python
     # Quick searches
     Restaurant.search_in(area="æ±äº¬", keyword="å¯¿å¸")
     Restaurant.near_station(station="æ¸‹è°·", distance="500m")
     Restaurant.by_genre(genre="ã‚¤ã‚¿ãƒªã‚¢ãƒ³", area="å…­æœ¬æœ¨")

     # Filters
     results.with_rating(min=4.0)
     results.with_price_under(5000)
     results.top(10)  # top 10 results
     ```

  4. **Better SearchResponse methods**:
     ```python
     # Current: manually filter
     high_rated = [r for r in response.restaurants if r.rating and r.rating >= 4.0]

     # Proposed
     response.filter(min_rating=4.0)
     response.filter(lambda r: r.review_count and r.review_count > 100)
     response.sort_by("rating", reverse=True)
     response.top(10)
     response.to_json()
     response.to_csv("results.csv")
     response.to_dataframe()  # pandas DataFrame if available
     ```

  5. **Custom exceptions**:
     ```python
     class TabelogError(Exception): pass
     class RateLimitError(TabelogError): pass
     class ParseError(TabelogError): pass
     class InvalidParameterError(TabelogError): pass
     ```

  6. **Type aliases for clarity**:
     ```python
     type ReservationDate = str  # YYYYMMDD
     type ReservationTime = str  # HHMM
     type RestaurantURL = str
     ```

  7. **Async context manager support**:
     ```python
     async with TabelogClient() as client:
         results = await client.search(area="æ±äº¬", keyword="å¯¿å¸")
     ```

  8. **Better parameter validation**:
     ```python
     # Validate ranges
     if party_size and not (1 <= party_size <= 100):
         raise InvalidParameterError("party_size must be between 1 and 100")

     # Validate page
     if page < 1:
         raise InvalidParameterError("page must be >= 1")
     ```

  9. **Simplified quick search function**:
     ```python
     # Current: 14 parameters
     query_restaurants(area=..., keyword=..., ...)

     # Proposed: accept **kwargs or use builder
     search(area="æ±äº¬", keyword="å¯¿å¸", min_rating=4.0)
     # or
     quick_search("æ±äº¬ å¯¿å¸", filters={"min_rating": 4.0})
     ```

  10. **Result pagination helpers**:
      ```python
      # Iterator for all pages
      async for restaurant in search.iter_all_pages():
          print(restaurant.name)

      # Or
      response.next_page()
      response.prev_page()
      ```

- **Restaurant detail page scraping**: Extend scraping capabilities beyond search results
  - **Current limitation**: Only scrapes restaurant list pages, not individual restaurant pages
  - **New features needed**:
    - Scrape restaurant detail URL (already in `Restaurant.url`)
    - Parse multiple tab pages on Tabelog:
      - åŸºæœ¬æƒ…å ± (basic info): hours, holidays, seating, payment methods, etc.
      - å£ã‚³ãƒŸ (reviews): user reviews, ratings, visit dates, detailed comments
      - ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (menu): dish names, prices, photos
      - ã‚³ãƒ¼ã‚¹ (courses): set menus, prices, course details
      - å†™çœŸ (photos): restaurant/food photos with captions
  - **New data models** (src/tabelog/detail.py or src/tabelog/models.py):
    ```python
    @dataclass
    class Review:
        reviewer: str
        rating: float
        visit_date: str | None
        title: str
        content: str
        helpful_count: int
        photos: list[str]

    @dataclass
    class MenuItem:
        name: str
        price: str | None
        description: str | None
        photo_url: str | None
        category: str | None  # appetizer, main, dessert, etc.

    @dataclass
    class Course:
        name: str
        price: str
        description: str
        items: list[str]  # course items

    @dataclass
    class RestaurantDetail:
        restaurant: Restaurant  # basic info from search
        business_hours: dict[str, str]  # weekday -> hours
        holidays: str | None
        seating: int | None
        payment_methods: list[str]
        reviews: list[Review]
        menu_items: list[MenuItem]
        courses: list[Course]
    ```
  - **API design**:
    - `RestaurantDetailRequest(restaurant_url: str)` - fetch detail page
    - Methods: `fetch_reviews()`, `fetch_menu()`, `fetch_courses()`, `fetch_all()`
    - Support pagination for reviews (Tabelog has many pages of reviews)
  - **URL patterns** (examples):
    - Base: `https://tabelog.com/tokyo/A1234/A567890/12345678/`
    - Reviews: `https://tabelog.com/tokyo/A1234/A567890/12345678/dtlrvwlst/`
    - Menu: `https://tabelog.com/tokyo/A1234/A567890/12345678/dtlmenu/`
    - Courses: `https://tabelog.com/tokyo/A1234/A567890/12345678/course/`

## ğŸ“ Implementation Notes

### Technical Considerations
- **Restaurant detail scraping challenges**:
  - Different restaurants may have different tab availability (not all have menu/course pages)
  - Need robust error handling for missing/malformed data
  - Review pagination can be extensive (100+ pages for popular restaurants)
  - Consider rate limiting to avoid being blocked by Tabelog
  - CSS selectors may differ between main page and detail pages
  - Some content may be behind login walls or require JavaScript rendering
  - Photos may be lazy-loaded or in different formats
- **TUI performance**:
  - Async/await critical for non-blocking UI during scraping
  - Cache detail page data to avoid re-scraping on navigation
  - Implement loading spinners/progress indicators during fetch
  - Consider background pre-fetching for selected restaurants in list

- **Production readiness**:
  - Add logging with different levels (DEBUG, INFO, WARNING, ERROR)
  - Metrics and monitoring hooks (request count, response time, error rate)
  - Health check endpoint for MCP server
  - Graceful degradation when Tabelog is down or changes HTML structure
  - Configuration file support (.tabelogrc, environment variables)

- **Developer experience**:
  - Type stubs for better IDE autocomplete
  - Docstrings on all public methods (Google style)
  - Usage examples in docstrings
  - Pre-commit hooks for code quality
  - GitHub Actions for CI/CD
  - Auto-publish to PyPI on tag

- **Security considerations**:
  - Sanitize user input to prevent injection attacks
  - Validate URLs before scraping
  - Don't log sensitive information (API keys if added)
  - Respect robots.txt (add parser)
  - Add User-Agent rotation to avoid detection
  - HTTPS only (no HTTP fallback)

### Research Needed
- **Best practices for Python API design**:
  - Study popular scraping libraries: `requests`, `httpx`, `scrapy`, `beautifulsoup4`
  - Study data query libraries: `sqlalchemy`, `peewee`, `django ORM` for builder patterns
  - Study async libraries: `asyncio`, `aiohttp` for async context managers
  - Python API design guidelines: PEP 8, Google Python Style Guide
  - Examples of fluent APIs in Python: `pandas`, `sqlalchemy`, `httpx`

- **Tabelog website structure**:
  - Explore detail page HTML structure for reviews, menus, courses
  - Identify all possible CSS selectors and their fallbacks
  - Test pagination limits (max pages per search)
  - Check for API endpoints (GraphQL, REST) if any
  - Analyze JavaScript rendering requirements
  - Document URL patterns for different page types

- **Anti-scraping measures**:
  - Study Tabelog's rate limiting policies
  - Test different User-Agent strings
  - Check robots.txt compliance
  - Research if login is required for certain data
  - Investigate CAPTCHA triggers
  - Test IP blocking thresholds

- **Competitive analysis**:
  - How do other Tabelog scrapers handle these issues?
  - What features do similar libraries offer?
  - Check PyPI for existing Tabelog packages
  - Study API design of: `yelp-fusion`, `google-places`, `tripadvisor-api`

## âœ… Completed

- **Area filtering and suggestion system** (2025-12-29)
  - âœ“ Fixed critical bug: Tabelog's `/rst/rstsearch?sa=area` does NOT filter by area
  - âœ“ Implemented path-based URL filtering (e.g., `/tokyo/rstLst/` instead of `/rst/rstsearch?sa=æ±äº¬`)
  - âœ“ Created `area_mapping.py` with mappings for all 47 prefectures
  - âœ“ Added `get_area_slug()` function to convert area names to URL slugs
  - âœ“ Updated `RestaurantSearchRequest.search()` to use area slug paths
  - âœ“ Updated `SearchRequest.search()` to use area slug paths
  - âœ“ Integrated Tabelog's internal suggest API (`/internal_api/suggest_form_words`)
  - âœ“ Created `suggest.py` with `AreaSuggestion` dataclass and async/sync functions
  - âœ“ Added `AreaSuggestModal` to TUI with F2 hotkey
  - âœ“ Visual feedback for suggestion loading (ğŸ”/âœ…/âŒ icons)
  - âœ“ Modal UI with OptionList for area/station selection
  - âœ“ Prefecture-level filtering now works accurately (no more national results)
  - âœ“ All code quality checks passing (ruff, ty)
  - âœ“ Documentation updated (CLAUDE.md, README.md, TUI_USAGE.md)
  - Note: City/station-level filtering not supported (Tabelog limitation)

- **Terminal UI (TUI) for interactive restaurant search** (2025-12-28/29)
  - âœ“ Created interactive terminal UI using Textual framework
  - âœ“ Search panel with area and keyword input
  - âœ“ RadioButton-based sorting selection (è©•åˆ†æ’å/è©•è«–æ•¸/æ–°é–‹å¹•/æ¨™æº–)
  - âœ“ Two-column layout: Results table (left) + Detail panel (right)
  - âœ“ Worker lifecycle management (auto-cancel previous search to prevent hanging)
  - âœ“ Tabelog native API sorting (SortType passed to backend)
  - âœ“ Results table (DataTable) displaying restaurant list
  - âœ“ Detail panel showing selected restaurant information
  - âœ“ Keyboard shortcuts: q (quit), s (search), r (results), d (detail)
  - âœ“ Async search integration for non-blocking UI
  - âœ“ CLI command: `tabelog tui`
  - âœ“ Clean and responsive dark theme with simplified styling
  - âœ“ Auto-height search panel to prevent clipping
  - âœ“ All 78 tests passing
  - âœ“ Type checking passing
  - Note: Advanced features like tab-based detail navigation, export, and filtering can be added later

- **Restaurant detail page scraping** (2025-12-28)
  - âœ“ Created comprehensive scraping for restaurant detail pages
  - âœ“ New dataclasses: `RestaurantDetail`, `Review`, `MenuItem`, `Course`
  - âœ“ Support for scraping multiple tabs: å£ã‚³ãƒŸ (reviews), ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (menu), ã‚³ãƒ¼ã‚¹ (courses)
  - âœ“ `RestaurantDetailRequest` class with sync/async support
  - âœ“ Pagination support for reviews (configurable max_review_pages)
  - âœ“ Selective fetching (can choose which tabs to scrape)
  - âœ“ Robust HTML parsing with BeautifulSoup
  - âœ“ Full test coverage (20 new tests)
  - âœ“ All 78 tests passing
  - âœ“ Type checking passing
  - Note: å†™çœŸ (photos) tab not implemented (excluded from requirements)

- **Core API improvements for better developer experience** (2025-12-28)
  - âœ“ Created custom exception classes (TabelogError, ParseError, InvalidParameterError, NetworkError, RateLimitError)
  - âœ“ Added type aliases (ReservationDate, ReservationTime, RestaurantURL)
  - âœ“ Renamed methods: do()/do_sync() â†’ search()/search_sync() (keeping old names for backward compatibility)
  - âœ“ Improved parameter validation with better error messages
  - âœ“ Added useful methods to SearchResponse:
    - filter() - filter restaurants by rating, review count, or custom condition
    - sort_by() - sort by any field
    - top() - get top N results
    - to_json() - export to JSON string
    - to_dict() - convert to dictionary
  - âœ“ Updated all tests to use new API
  - âœ“ Updated examples to use new API
  - âœ“ All 58 tests passing
  - âœ“ Code quality checks passing (ruff, type hints)

- **Package renamed from `tabelogmcp` to `tabelog`** (2025-12-28)
  - Updated package name in pyproject.toml
  - Renamed src/tabelogmcp/ â†’ src/tabelog/
  - Updated all imports in tests and examples
  - Updated CLAUDE.md and IDEAS.md references
  - Created basic CLI entry point (tabelog.cli:main)
  - All tests passing âœ“

- **HTML parsing improvements for Tabelog format changes** (2025-12-29)
  - âœ“ Updated restaurant.py to handle new Tabelog HTML structure
  - âœ“ Fixed area/genre parsing for format: `<div class="list-rst__area-genre"> [ç¸£] å¸‚å€ / é¡å‹</div>`
  - âœ“ Removed test-specific hacks (auto-generated station/distance/genres)
  - âœ“ Maintained backward compatibility with multiple HTML formats
  - âœ“ Updated all test fixtures and assertions
  - âœ“ All 78 tests passing
  - âœ“ Code quality checks passing (ruff, ty)
  - âœ“ Test coverage: 71% overall, 87-94% on core modules

---
**Note**: This is a living document. Feel free to add, modify, or reorganize ideas as the project evolves.
